{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vv4QteT9FlBQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 1\n",
        "\n",
        "**Problem Statement**\n",
        "\n",
        "**Title:** Predicting Loan Defaults Using Machine Learning\n",
        "\n",
        "**Objective:** The primary goal of this project is to develop a predictive model that accurately forecasts the likelihood of loan default by individual borrowers. By leveraging historical data and relevant features, the model will help financial institutions mitigate risks, optimize lending decisions, and enhance credit evaluation processes.\n",
        "\n",
        "**Key Questions:**\n",
        "\n",
        "What are the most significant factors contributing to loan defaults?\n",
        "How accurately can we predict loan defaults using historical data?\n",
        "What patterns or trends in borrower behavior are indicative of potential default?\n",
        "Scope: The model will focus on predicting defaults on personal loans, mortgages, or other forms of credit extended by financial institutions. It will take into account various borrower characteristics, loan details, and external factors to assess the risk associated with each loan.\n",
        "\n",
        "**Data Collection Plan**\n",
        "1. Personal Details of Applicants\n",
        "\n",
        "Types of Data:\n",
        "Age\n",
        "Gender\n",
        "Marital status\n",
        "Employment status\n",
        "Income level\n",
        "Educational background\n",
        "Residential status (e.g., homeowner, renter)\n",
        "Sources:\n",
        "Financial institution’s internal records\n",
        "Loan application forms\n",
        "Customer surveys\n",
        "2. Credit Scores\n",
        "\n",
        "Types of Data:\n",
        "Credit score\n",
        "Credit history length\n",
        "Number of open accounts\n",
        "History of late payments\n",
        "Sources:\n",
        "Credit bureaus (e.g., Equifax, TransUnion, Experian)\n",
        "Financial institution’s internal credit assessment tools\n",
        "3. Loan Details\n",
        "\n",
        "Types of Data:\n",
        "Loan amount\n",
        "Loan purpose\n",
        "Interest rate\n",
        "Loan term\n",
        "Repayment schedule\n",
        "Sources:\n",
        "Financial institution’s internal loan records\n",
        "Loan agreements\n",
        "4. Repayment History\n",
        "\n",
        "Types of Data:\n",
        "Payment dates\n",
        "Amount paid vs. amount due\n",
        "Missed payments\n",
        "Early repayments\n",
        "Sources:\n",
        "Financial institution’s internal payment tracking systems\n",
        "Payment gateways\n",
        "5. Financial Behavior\n",
        "\n",
        "Types of Data:\n",
        "Savings and checking account balances\n",
        "Spending habits\n",
        "Investment portfolios\n",
        "Recent large transactions\n",
        "Sources:\n",
        "Bank account statements\n",
        "Financial institution’s internal transaction records\n",
        "6. Employment and Income Stability\n",
        "\n",
        "Types of Data:\n",
        "Employer name and industry\n",
        "Job tenure\n",
        "Income trends (e.g., salary increases, bonuses)\n",
        "Frequency of job changes\n",
        "Sources:\n",
        "Employment records\n",
        "Payroll systems\n",
        "Self-reported information on loan applications\n",
        "7. External Economic Factors\n",
        "\n",
        "Types of Data:\n",
        "Unemployment rate\n",
        "Inflation rate\n",
        "Interest rate fluctuations\n",
        "Economic growth indicators (e.g., GDP)\n",
        "Sources:\n",
        "Government economic reports\n",
        "Central bank data\n",
        "Financial news sources\n",
        "8. Demographic and Geographic Information\n",
        "\n",
        "Types of Data:\n",
        "Geographic location (e.g., state, city, neighborhood)\n",
        "Population demographics (e.g., average income, unemployment rate in the area)\n",
        "Crime rates\n",
        "Sources:\n",
        "Public census data\n",
        "Government demographic reports\n",
        "Local economic studies"
      ],
      "metadata": {
        "id": "SVYcYMu-Fsxl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 2\n",
        "\n",
        "**Feature Selection for Loan Default Prediction**\n",
        "\n",
        "**Objective:** To identify the most relevant features from the dataset that are likely to influence loan default prediction. The goal is to select features that have the strongest predictive power while avoiding multicollinearity and overfitting.\n",
        "\n",
        "1. Credit Score\n",
        "\n",
        "Relevance: A borrower's credit score is one of the most significant indicators of their creditworthiness. It reflects their history of managing debt and making timely payments, directly correlating with their likelihood of default.\n",
        "\n",
        "Justification: High credit scores generally indicate low risk, while low credit scores suggest a higher risk of default. This feature is crucial for assessing the borrower's financial responsibility and past behavior.\n",
        "\n",
        "2. Repayment History\n",
        "\n",
        "Relevance: This feature tracks the borrower's history of making loan payments on time or missing payments. It provides direct evidence of their behavior regarding debt repayment.\n",
        "\n",
        "Justification: A strong repayment history implies reliability, while frequent missed payments or late payments indicate a higher risk of default. It's a key indicator of potential default behavior.\n",
        "\n",
        "3. Debt-to-Income Ratio (DTI)\n",
        "\n",
        "Relevance: The debt-to-income ratio measures the proportion of a borrower’s income that goes towards debt repayment. It helps in understanding the borrower's financial burden relative to their income.\n",
        "\n",
        "Justification: A high DTI ratio suggests that the borrower has less disposable income available to meet their financial obligations, increasing the risk of default. Conversely, a low DTI indicates better financial stability.\n",
        "\n",
        "4. Loan Amount\n",
        "\n",
        "Relevance: The size of the loan is a critical factor, as larger loans may be more difficult to repay, especially if the borrower's financial situation changes.\n",
        "\n",
        "Justification: Higher loan amounts increase the repayment burden on the borrower, which can lead to a higher probability of default if their income does not grow proportionately or if they face financial hardships.\n",
        "\n",
        "5. Employment Status and Stability\n",
        "\n",
        "Relevance: Employment status (e.g., full-time, part-time, unemployed) and job stability (e.g., tenure with the current employer) provide insight into the borrower’s income security.\n",
        "\n",
        "Justification: Stable employment typically correlates with consistent income, reducing the risk of default. Unstable employment or frequent job changes may indicate potential income disruptions, increasing default risk.\n",
        "\n",
        "6. Income Level\n",
        "\n",
        "Relevance: The borrower's income level is directly related to their ability to meet financial obligations, including loan repayments.\n",
        "\n",
        "Justification: Higher income generally enables borrowers to manage their debt more effectively, reducing the likelihood of default. Lower income can strain the borrower's ability to make timely payments, particularly for larger loans.\n",
        "\n",
        "7. Age\n",
        "\n",
        "Relevance: Age can be associated with financial maturity and stability, influencing borrowing and repayment behavior.\n",
        "\n",
        "Justification: Younger borrowers may have less financial experience, potentially leading to higher default rates. Conversely, older borrowers might have more financial stability but could face retirement-related income reductions, affecting their ability to repay loans.\n",
        "\n",
        "8. Loan Term\n",
        "Relevance: The length of time over which the loan must be repaid can impact the borrower's ability to manage payments.\n",
        "\n",
        "Justification: Shorter loan terms mean higher monthly payments, which could increase the risk of default if the borrower’s cash flow is insufficient. Longer terms may reduce monthly payments but increase the overall interest burden, which could also affect default risk.\n",
        "\n",
        "9. Previous Defaults or Bankruptcies\n",
        "\n",
        "Relevance: A history of defaulting on previous loans or declaring bankruptcy is a strong indicator of potential future defaults.\n",
        "\n",
        "Justification: Borrowers with past defaults or bankruptcies have demonstrated difficulty managing debt, making them higher-risk candidates for defaulting on new loans.\n",
        "\n",
        "10. Residential Status\n",
        "\n",
        "Relevance: Whether the borrower owns or rents their home can provide insights into their financial stability and asset ownership.\n",
        "\n",
        "Justification: Homeowners might have more financial stability and assets, reducing their risk of default. Renters might have less financial stability, particularly if their rent is a significant portion of their income.\n",
        "Model\n",
        "Choice Justification:\n",
        "\n",
        "For predicting loan defaults, Logistic Regression and Random Forests are two strong contenders:\n",
        "\n",
        "Logistic Regression:\n",
        "\n",
        "Why: It is a robust method for binary classification problems like loan default prediction (default/no default). It provides clear insights into the influence of each feature, which is crucial for financial models that require interpretability.\n",
        "\n",
        "Strengths: Easy to implement and interpret. Provides probabilities of default, which can be useful for risk assessment.\n",
        "\n",
        "Random Forest:\n",
        "\n",
        "Why: It handles non-linear relationships and interactions between features better than Logistic Regression. It can automatically handle feature importance, giving insights into which features are most predictive.\n",
        "\n",
        "Strengths: High accuracy, handles large datasets well, and is less prone to overfitting due to the ensemble nature.\n",
        "\n"
      ],
      "metadata": {
        "id": "221d4DB5Gg32"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 3\n",
        "\n",
        "**Objective:** To outline the steps for training, evaluating, and optimizing the predictive model for loan defaults. The focus is on selecting appropriate metrics to assess the model's performance and applying techniques to improve accuracy, robustness, and generalizability.\n",
        "\n",
        "1. Data Preparation\n",
        "\n",
        "Train-Test Split:\n",
        "\n",
        "Action: Divide the dataset into a training set (typically 70-80%) and a test set (20-30%) to evaluate the model’s performance on unseen data.\n",
        "\n",
        "Goal: Ensure that the model generalizes well to new data and avoids overfitting.\n",
        "\n",
        "Data Preprocessing:\n",
        "\n",
        "Action: Handle missing values, normalize/standardize numerical features, and encode categorical variables.\n",
        "\n",
        "Goal: Prepare the data for model training, ensuring that the features are in a format that the model can effectively utilize.\n",
        "\n",
        "2. Model Training\n",
        "\n",
        "Choose Initial Model:\n",
        "\n",
        "Action: Start with Logistic Regression or Random Forest as a baseline model.\n",
        "Goal: Establish a benchmark for model performance.\n",
        "\n",
        "Hyperparameter Tuning:\n",
        "\n",
        "Action: Use techniques like Grid Search or Random Search with Cross-Validation to find the optimal hyperparameters.\n",
        "\n",
        "Goal: Improve model performance by selecting the best combination of hyperparameters.\n",
        "\n",
        "3. Model Evaluation\n",
        "\n",
        "Key Metrics:\n",
        "\n",
        "Accuracy\n",
        "\n",
        "Description: Measures the proportion of correctly predicted instances out of the total instances.\n",
        "\n",
        "Relevance: Provides a general measure of how often the model is correct. However, it may not be sufficient on its own, especially in cases of imbalanced datasets.\n",
        "\n",
        "Formula:\n",
        "Accuracy\n",
        "=\n",
        "True Positives\n",
        "+\n",
        "True Negatives\n",
        "Total Number of Instances\n",
        "Accuracy=\n",
        "Total Number of Instances\n",
        "True Positives+True Negatives\n",
        "​\n",
        "\n",
        "Limitations: High accuracy can be misleading if the dataset is imbalanced (e.g., if defaults are rare).\n",
        "\n",
        "Precision\n",
        "\n",
        "Description: Measures the proportion of correctly predicted positive instances (defaults) out of all instances predicted as positive.\n",
        "\n",
        "Relevance: Important in minimizing false positives, which in this context are cases where the model incorrectly predicts a borrower will default when they will not.\n",
        "\n",
        "Formula:\n",
        "Precision\n",
        "=\n",
        "True Positives\n",
        "True Positives\n",
        "+\n",
        "False Positives\n",
        "Precision=\n",
        "True Positives+False Positives\n",
        "True Positives\n",
        "​\n",
        "\n",
        "Use Case: Useful when the cost of a false positive (e.g., denying a loan to a good borrower) is high.\n",
        "\n",
        "Recall (Sensitivity or True Positive Rate)\n",
        "\n",
        "Description: Measures the proportion of actual positive instances (defaults) that the model correctly identifies.\n",
        "\n",
        "Relevance: Important for identifying as many actual defaults as possible, minimizing false negatives.\n",
        "\n",
        "Formula:\n",
        "Recall\n",
        "=\n",
        "True Positives\n",
        "True Positives\n",
        "+\n",
        "False Negatives\n",
        "Recall=\n",
        "True Positives+False Negatives\n",
        "True Positives\n",
        "​\n",
        "\n",
        "Use Case: Critical in scenarios where missing a true default (false negative) has serious consequences for the lender.\n",
        "\n",
        "F1 Score\n",
        "\n",
        "Description: The harmonic mean of precision and recall, providing a balance between the two metrics.\n",
        "\n",
        "Relevance: Useful when you need to balance the importance of precision and recall, especially in cases where the dataset is imbalanced.\n",
        "\n",
        "Formula:\n",
        "𝐹\n",
        "1\n",
        "=\n",
        "2\n",
        "×\n",
        "Precision\n",
        "×\n",
        "Recall\n",
        "Precision\n",
        "+\n",
        "Recall\n",
        "F1=2×\n",
        "Precision+Recall\n",
        "Precision×Recall\n",
        "​\n",
        "\n",
        "Use Case: Provides a single metric that balances the trade-off between precision and recall.\n",
        "\n",
        "AUC-ROC (Area Under the Receiver Operating Characteristic Curve)\n",
        "\n",
        "Description: Measures the model's ability to distinguish between classes (default vs. no default) across all classification thresholds.\n",
        "\n",
        "Relevance: AUC-ROC provides insight into the model's ability to differentiate between borrowers who will default and those who will not, regardless of the threshold chosen.\n",
        "\n",
        "Use Case: Ideal for comparing models; the closer the AUC-ROC is to 1, the better the model performs.\n",
        "\n",
        "Confusion Matrix\n",
        "\n",
        "Description: A table that provides the number of true positives, false positives, true negatives, and false negatives.\n",
        "\n",
        "Relevance: Helps visualize the model’s performance and understand the distribution of predictions.\n",
        "\n",
        "Use Case: Useful for gaining a detailed understanding of the types of errors the model is making.\n",
        "\n",
        "4. Model Optimization\n",
        "\n",
        "Cross-Validation:\n",
        "\n",
        "Action: Perform k-fold cross-validation to evaluate the model’s performance on different subsets of the data.\n",
        "\n",
        "Goal: Ensure that the model performs consistently across various splits of the data and is not overfitting to a particular subset.\n",
        "\n",
        "Hyperparameter Tuning:\n",
        "\n",
        "Action: Fine-tune hyperparameters using techniques like Grid Search or Random Search in combination with cross-validation.\n",
        "\n",
        "Goal: Improve model performance by selecting the optimal hyperparameters.\n",
        "\n",
        "Feature Engineering:\n",
        "\n",
        "Action: Create new features or modify existing ones based on domain knowledge or exploratory data analysis.\n",
        "\n",
        "Goal: Enhance the model's ability to capture underlying patterns in the data.\n",
        "\n",
        "Model Ensemble:\n",
        "\n",
        "Action: Combine predictions from multiple models (e.g., Logistic Regression, Random Forest, Gradient Boosting) to improve performance.\n",
        "\n",
        "Goal: Reduce model variance and improve overall prediction accuracy.\n",
        "\n",
        "5. Final Model Evaluation on Test Data\n",
        "\n",
        "Action: After optimizing the model on the training data, evaluate it on the test set using the metrics mentioned above.\n",
        "\n",
        "Goal: Assess the model’s performance on unseen data to estimate how it will perform in real-world scenarios.\n",
        "\n",
        "Threshold Adjustment:\n",
        "\n",
        "Action: Adjust the classification threshold based on the business context (e.g., the cost of false positives vs. false negatives).\n",
        "\n",
        "Goal: Optimize the model’s predictions according to specific business needs.\n",
        "\n",
        "6. Interpretability and Reporting\n",
        "\n",
        "Feature Importance Analysis:\n",
        "\n",
        "Action: Analyze the importance of each feature in the final model.\n",
        "\n",
        "Goal: Understand which features are most influential in predicting defaults, providing insights for business decisions.\n",
        "\n",
        "Reporting:\n",
        "\n",
        "Action: Prepare a detailed report that includes the model’s performance metrics, key findings, and recommendations for deployment.\n",
        "\n",
        "Goal: Communicate the model’s effectiveness and any business implications to stakeholders."
      ],
      "metadata": {
        "id": "iRO936lLG_Ts"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 4\n",
        "\n",
        "1. Predicting Stock Prices: Predict Future Prices\n",
        "\n",
        "Type of Machine Learning: Supervised Learning (Regression)\n",
        "\n",
        "Explanation:\n",
        "\n",
        "Supervised Learning is suitable here because the goal is to predict a continuous variable—stock prices—based on historical data.\n",
        "\n",
        "Regression is the specific technique within supervised learning that would be used to predict future stock prices based on past trends, patterns, and other numerical inputs like historical prices, volumes, and possibly other market indicators.\n",
        "\n",
        "2. Organizing a Library of Books: Group Books into Genres or Categories Based on Similarities\n",
        "\n",
        "Type of Machine Learning: Unsupervised Learning (Clustering)\n",
        "\n",
        "Explanation:\n",
        "\n",
        "Unsupervised Learning is appropriate when the goal is to discover the inherent structure in data without predefined labels.\n",
        "\n",
        "Clustering is the specific method that would group books into genres or categories based on similarities in their features, such as text content, author, publication year, and other metadata.\n",
        "\n",
        "\n",
        "3. Program a Robot to Navigate and Find the Shortest Path in a Maze\n",
        "\n",
        "Type of Machine Learning: Reinforcement Learning\n",
        "\n",
        "Explanation:\n",
        "\n",
        "Reinforcement Learning (RL) is the most suitable approach for this scenario, as it involves an agent (the robot) learning to take actions in an environment (the maze) to maximize some notion of cumulative reward (reaching the goal or finding the shortest path).\n",
        "\n",
        "In Reinforcement Learning, the robot would learn to navigate the maze by exploring different paths and receiving rewards for actions that bring it closer to the goal or penalties for actions that lead to dead ends."
      ],
      "metadata": {
        "id": "3LeYdkjmIN6P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 5\n",
        "\n",
        "**Evaluation Strategies for Different Machine Learning Models**\n",
        "\n",
        "1. **Supervised Learning:** Classification Model (e.g., Logistic Regression)\n",
        "\n",
        "Evaluation Strategy:\n",
        "\n",
        "Key Metrics:\n",
        "\n",
        "Accuracy: Measures the proportion of correctly classified instances out of the total instances.\n",
        "\n",
        "Challenge: Accuracy alone may not be sufficient, especially in cases of imbalanced datasets where one class dominates.\n",
        "\n",
        "Precision: Indicates how many of the instances predicted as positive are actually positive.\n",
        "\n",
        "Challenge: High precision can come at the cost of recall, especially in cases where minimizing false positives is crucial.\n",
        "\n",
        "Recall: Measures how many actual positive instances were correctly identified by the model.\n",
        "\n",
        "Challenge: High recall can come at the cost of precision, leading to more false positives.\n",
        "\n",
        "F1-Score: The harmonic mean of precision and recall, providing a single metric that balances both.\n",
        "\n",
        "Challenge: F1-Score can be difficult to interpret if precision and recall are both low.\n",
        "\n",
        "ROC-AUC (Receiver Operating Characteristic - Area Under Curve): Evaluates the model's ability to distinguish between classes across various thresholds.\n",
        "\n",
        "Challenge: ROC-AUC can sometimes be misleading if the dataset is highly imbalanced.\n",
        "\n",
        "Evaluation Methods:\n",
        "\n",
        "Cross-Validation: Use k-fold cross-validation to assess the model's performance across different subsets of the data, ensuring that the results are consistent and not dependent on a particular train-test split.\n",
        "\n",
        "Challenge: Cross-validation can be computationally expensive, especially with large datasets.\n",
        "\n",
        "Confusion Matrix: Provides a detailed breakdown of true positives, false positives, true negatives, and false negatives.\n",
        "\n",
        "Challenge: Interpreting confusion matrices can be complex, especially with multi-class problems.\n",
        "\n",
        "ROC Curves: Visualize the trade-off between true positive rate and false positive rate, helping in selecting an appropriate classification threshold.\n",
        "\n",
        "Challenge: Interpreting ROC curves can be less intuitive, particularly when comparing multiple models.\n",
        "\n",
        "Limitations:\n",
        "\n",
        "Metrics like accuracy and ROC-AUC might not fully capture the model’s effectiveness in real-world scenarios, especially if there is a significant class imbalance.\n",
        "\n",
        "Cross-validation provides a robust evaluation but can be time-consuming for large datasets.\n",
        "\n",
        "2. Unsupervised Learning: Clustering Model (e.g., K-Means Clustering)\n",
        "\n",
        "Evaluation Strategy:\n",
        "\n",
        "Key Metrics:\n",
        "\n",
        "Silhouette Score: Measures how similar an object is to its own cluster compared to other clusters. Values close to +1 indicate that the object is well matched to its cluster, while values close to -1 indicate that it may belong to a different cluster.\n",
        "\n",
        "Challenge: The silhouette score may not always be informative if the clusters are not well-separated.\n",
        "\n",
        "Elbow Method: Plots the total within-cluster sum of square (WCSS) against the number of clusters. The \"elbow\" point is where adding more clusters doesn't significantly improve model performance.\n",
        "\n",
        "Challenge: The elbow point might not be clearly defined, making it difficult to choose the optimal number of clusters.\n",
        "\n",
        "Davies-Bouldin Index: Measures the average similarity ratio of each cluster with the cluster that is most similar to it. Lower values indicate better clustering.\n",
        "\n",
        "Challenge: Sensitive to noise and outliers, which can skew the results.\n",
        "Cluster Validation Indices: These include various metrics like Dunn Index, Calinski-Harabasz Index, etc., that assess the compactness and separation of clusters.\n",
        "\n",
        "Challenge: Different indices might suggest different numbers of clusters, leading to ambiguity.\n",
        "\n",
        "Evaluation Methods:\n",
        "\n",
        "Visual Inspection: Plotting clusters in 2D or 3D space to assess how well the data points are separated visually.\n",
        "\n",
        "Challenge: Visual inspection is limited to datasets with low dimensionality and might not capture the true structure in high-dimensional data.\n",
        "\n",
        "Internal Validation: Using metrics like the silhouette score, elbow method, and Davies-Bouldin Index to assess the quality of clustering without ground truth labels.\n",
        "\n",
        "Challenge: Internal validation metrics might not always align with the true usefulness of clusters in the given application.\n",
        "\n",
        "External Validation: If ground truth labels are available, compare the clusters to the actual classes using metrics like Adjusted Rand Index or Normalized Mutual Information.\n",
        "\n",
        "Challenge: Requires ground truth labels, which may not be available in many unsupervised learning tasks.\n",
        "\n",
        "Limitations:\n",
        "\n",
        "Evaluating clustering models is inherently challenging due to the lack of ground truth labels, making it difficult to determine the “correct” number of clusters.\n",
        "\n",
        "Many clustering metrics are sensitive to the scale of the data and the presence of noise, which can lead to misleading results.\n",
        "\n",
        "3. Reinforcement Learning: Robot Navigation in a Maze\n",
        "\n",
        "Evaluation Strategy:\n",
        "\n",
        "Key Metrics:\n",
        "\n",
        "Cumulative Reward: Measures the total reward accumulated by the agent (robot) over time. The higher the cumulative reward, the better the agent's performance.\n",
        "Challenge: Accumulating high rewards early on might not always mean optimal learning, especially if the environment is complex and rewards are sparse.\n",
        "\n",
        "Convergence: The point at which the agent’s performance stabilizes and stops improving significantly with further training.\n",
        "\n",
        "Challenge: Convergence might be slow or might occur prematurely, leading to suboptimal policies.\n",
        "\n",
        "Exploration vs. Exploitation Balance: Evaluates how well the agent balances trying new actions (exploration) versus sticking to known rewarding actions (exploitation).\n",
        "\n",
        "Challenge: Too much exploration can slow down learning, while too much exploitation can lead to getting stuck in local optima.\n",
        "\n",
        "Evaluation Methods:\n",
        "\n",
        "Training Episode Analysis: Monitor the agent’s performance over multiple training episodes to ensure it is learning effectively and rewards are improving over time.\n",
        "\n",
        "Challenge: Early training episodes might show high variance in performance, making it hard to assess progress.\n",
        "\n",
        "Policy Evaluation: Test the learned policy by running the agent through the environment and measuring the average reward over multiple trials.\n",
        "\n",
        "Challenge: If the environment is highly stochastic, performance might vary significantly between trials, making it hard to assess policy effectiveness.\n",
        "\n",
        "Generalization Test: Evaluate the agent’s performance on slightly modified environments to ensure it has learned a robust policy that generalizes beyond the training environment.\n",
        "\n",
        "Challenge: Generalization might be poor if the agent has overfitted to the specific training environment.\n",
        "\n",
        "Limitations:\n",
        "\n",
        "Reinforcement learning models can be difficult to evaluate due to the complexity of the environment and the variability in agent performance across episodes.\n",
        "\n",
        "Cumulative reward and convergence metrics might not fully capture the agent’s ability to adapt to new or changing environments, making it hard to ensure the model’s robustness."
      ],
      "metadata": {
        "id": "14tvrHoWIqrn"
      }
    }
  ]
}